{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1H5lt4CRe2aD_10k9nt6lYrq0WvN0-3hZ",
      "authorship_tag": "ABX9TyPGbisdVS6/KS9FQoUJ2sIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakuni-Weerasinghe/Automatic-Question-and-Answer-Generation-based-on-Large-Language-Models/blob/master/Relavance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "gkXQDkdwXkyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "Tg14bvPCXnAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = '1B8D7kRJdaLJf4NFDWCU3yxySfJFUAJo-'\n",
        "output_file = 'dataset.txt'\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file, quiet=False)\n"
      ],
      "metadata": {
        "id": "2XoEGW3EXpRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Read the dataset from the .txt file\n",
        "with open('dataset.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Shuffle the lines randomly\n",
        "random.shuffle(lines)\n",
        "\n",
        "# Split the dataset into training and dev sets (e.g., 80% training, 20% dev)\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(lines) * split_ratio)\n",
        "\n",
        "train_set = lines[:split_index]\n",
        "dev_set = lines[split_index:]\n",
        "\n",
        "# Write the training set to a new file\n",
        "with open('train.txt', 'w', encoding='utf-8') as train_file:\n",
        "    train_file.writelines(train_set)\n",
        "\n",
        "# Write the dev set to a new file\n",
        "with open('dev.txt', 'w', encoding='utf-8') as dev_file:\n",
        "    dev_file.writelines(dev_set)\n"
      ],
      "metadata": {
        "id": "xn14cK5W0lb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv train.txt dev.txt drive/MyDrive/Research/QG_Reward/Discriminators/Relevance/Data"
      ],
      "metadata": {
        "id": "vauO5cbZ2dG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1-2nxsXmCO9EPNeulepuGJee79ALk6APs/view?usp=sharing  relevance/dev\n",
        "# https://drive.google.com/file/d/1-9a5VM1a7Ars5gz70STiKtRkzKJ_dd2T/view?usp=sharing   relevance/train\n",
        "# https://drive.google.com/file/d/1x85bhKgE_3vpEGmbOCfkdOr9KNdO6S1D/view?usp=sharing  relevance/run.py\n",
        "\n",
        "# !gdown --id 1--1bYIViN5ih6ylIfOIuZNSlLYMar5Fp # relevance/dev\n",
        "# !gdown --id 1xyKbt3ZRztTn4jtQVlGn-olkRds0jrCy # relevance/train\n",
        "\n",
        "file_id_dev = '1-2nxsXmCO9EPNeulepuGJee79ALk6APs'\n",
        "file_id_train = '1-9a5VM1a7Ars5gz70STiKtRkzKJ_dd2T'\n",
        "file_id_relevance_run = '1x85bhKgE_3vpEGmbOCfkdOr9KNdO6S1D'\n",
        "\n",
        "output_file_train = 'train.txt'\n",
        "output_file_dev = 'dev.txt'\n",
        "output_file_relevance_run = 'run_model.py'\n",
        "\n",
        "#gdown.download(f'https://drive.google.com/uc?id={file_id_dev}', output_file_dev, quiet=False)\n",
        "#gdown.download(f'https://drive.google.com/uc?id={file_id_train}', output_file_train, quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_relevance_run}', output_file_relevance_run, quiet=False)"
      ],
      "metadata": {
        "id": "uvu03J7QX1XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Your data file\n",
        "file_path = 'train.txt'\n",
        "\n",
        "# Create a list to store data for each line\n",
        "data_lines = []\n",
        "\n",
        "# Read the file line by line and split by tabs\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Split the line by tabs and append to the list\n",
        "        data_lines.append(line.strip().split('          '))\n",
        "\n",
        "# Create a DataFrame from the list\n",
        "df = pd.DataFrame(data_lines)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "k1HaBTxIX40b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Update paths as needed\n",
        "DATAHOME = \"/content/datasets\"\n",
        "EXEHOME = \"/content/src\"\n",
        "MODELHOME = \"/content/models\"\n",
        "\n",
        "# Make directories\n",
        "os.makedirs(MODELHOME, exist_ok=True)\n",
        "\n",
        "# Change directory\n",
        "os.chdir(EXEHOME)\n",
        "\n",
        "# Set CUDA_VISIBLE_DEVICES\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "\n",
        "# Run Python script\n",
        "!python run_model.py \\\n",
        "       --model_name_or_path bert-base-cased \\\n",
        "       --model_type bert \\\n",
        "       --output_dir {MODELHOME} \\\n",
        "       --overwrite_output_dir \\\n",
        "       --tokenizer_name bert-base-uncased \\\n",
        "       --train_data_file {DATAHOME}/train.txt \\\n",
        "       --eval_data_file {DATAHOME}/dev.txt \\\n",
        "       --line_by_line \\\n",
        "       --learning_rate 2e-5 \\\n",
        "       --block_size 384 \\\n",
        "       --per_gpu_train_batch_size 16 \\\n",
        "       --per_gpu_eval_batch_size 8 \\\n",
        "       --do_train \\\n",
        "       --evaluate_during_training \\\n",
        "       --num_train_epochs 32\n"
      ],
      "metadata": {
        "id": "hxs-f8i2X9IC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}